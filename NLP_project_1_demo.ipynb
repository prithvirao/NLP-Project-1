{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND16CLafDJcfwry6THU3vL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prithvirao/NLP-Project-1/blob/main/NLP_project_1_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUj72iR_YrGP",
        "outputId": "4c909681-094a-412d-cc93-fb84ba397544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tweepy==3.7.0 in /usr/local/lib/python3.8/dist-packages (3.7.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.8/dist-packages (from tweepy==3.7.0) (2.25.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from tweepy==3.7.0) (1.15.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.8/dist-packages (from tweepy==3.7.0) (1.7.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tweepy==3.7.0) (1.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.11.1->tweepy==3.7.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.11.1->tweepy==3.7.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.11.1->tweepy==3.7.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.11.1->tweepy==3.7.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->tweepy==3.7.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install tweepy==3.7.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall nltk\n",
        "!pip install -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7tdYuHFY1gS",
        "outputId": "a9a21355-5b01-4326-ca76-3713a64a941a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: nltk 3.8.1\n",
            "Uninstalling nltk-3.8.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/nltk\n",
            "    /usr/local/lib/python3.8/dist-packages/nltk-3.8.1.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/nltk/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled nltk-3.8.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nltk\n",
            "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Installing collected packages: nltk\n",
            "Successfully installed nltk-3.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import re\n",
        "import nltk\n",
        "import math\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3iMjJfWZDeQ",
        "outputId": "f2c669c4-8329-41b7-8ead-525c0bdefe32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up Twitter API credentials\n",
        "consumer_key = \"skakU2irbEBd97RvhpBsW0sXL\"\n",
        "consumer_secret = \"Bgb8TuOlhCB0nRBpyJCMtKOLkvhuSW7D0V1EoJzf7p7McFwknf\"\n",
        "access_token = \"880363396016869376-fFRlVcD2l7sMDmpGZw3yZelKxijcwEP\"\n",
        "access_token_secret = \"l0QpT9WuWXHCV4on1C20irIzXYrtxIoHoJXHtSh7vxG4j\""
      ],
      "metadata": {
        "id": "iwkaWRjpZKAo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up API authentication\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)"
      ],
      "metadata": {
        "id": "qw3AZOyKZP5o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up API client\n",
        "api = tweepy.API(auth)"
      ],
      "metadata": {
        "id": "X7-0TDnCZR77"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMQZJNaWZT4o",
        "outputId": "0aaeab8e-3847-48ed-b303-cf3c994d2cbc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # remove urls\n",
        "    text = re.sub(r'\\#\\w+\\rt', '', text)  # remove hashtags\n",
        "    text = text.lower()  # convert to lowercase\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])  # remove stop words\n",
        "    return text"
      ],
      "metadata": {
        "id": "MtfIYqskZWwq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant tweets based on keywords and dates\n",
        "start_date = datetime.now() - timedelta(days=5)\n",
        "end_date = datetime.now()"
      ],
      "metadata": {
        "id": "GekfqoCiZacI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect tweets for each day\n",
        "for i in range((end_date - start_date).days):\n",
        "    day = start_date + timedelta(days=i)\n",
        "    date_str = day.strftime(\"%Y-%m-%d\")\n",
        "    \n",
        "    # Extract relevant tweets based on keywords\n",
        "    keywords = ['earthquake']\n",
        "    tweets = []\n",
        "    primary_locations={'testing':0}\n",
        "    location_summaries={}\n",
        "    for keyword in keywords:\n",
        "        for tweet in tweepy.Cursor(api.search, q=keyword, lang='en', tweet_mode='extended', until=date_str).items(100):\n",
        "            text = tweet.full_text\n",
        "            preprocessed_text = preprocess_text(text)\n",
        "            tweets.append(preprocessed_text)\n",
        "            \n",
        "            # Extract location entities from tweet text\n",
        "            doc = nlp(preprocessed_text)\n",
        "            locations = [ent.text for ent in doc.ents if ent.label_ == 'GPE']\n",
        "            \n",
        "            if len(locations)>1:\n",
        "              locations=[locations[0]]\n",
        "\n",
        "            for location in locations:\n",
        "              if location not in primary_locations:\n",
        "                primary_locations[location]=0\n",
        "              else:\n",
        "                primary_locations[location]=primary_locations[location]+1\n",
        "\n",
        "              if location not in location_summaries:\n",
        "                location_summaries[location] = []\n",
        "              location_summaries[location].append(preprocessed_text)\n",
        "            \n",
        "    print(primary_locations)\n",
        "    #print(primary_locations.values())\n",
        "    max_value = max(primary_locations.values())\n",
        "    #print(max_value) \n",
        "\n",
        "    threshold=math.floor(math.sqrt(max_value))\n",
        "\n",
        "    # Rank and summarize the relevant tweets using a machine learning-based model (T5)\n",
        "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "    model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "    \n",
        "    #prev_sum=\"\";\n",
        "    print()\n",
        "    print()\n",
        "    print(\"#\"*20)\n",
        "    print(f\"Summary for {date_str}:\")\n",
        "    print(\"#\"*20)\n",
        "    for location, location_tweets in location_summaries.items():\n",
        "        if primary_locations[location]>=threshold:\n",
        "          input_text = ' '.join(location_tweets)\n",
        "          input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "          summary_ids = model.generate(input_ids, num_beams=4, length_penalty=2.0, max_length=100, min_length=10, no_repeat_ngram_size=2)\n",
        "          summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "          #if prev_sum != summary:\n",
        "          print(f\"Summaries for {location}:\")\n",
        "          # Output summary for each location\n",
        "          print(summary)\n",
        "          print()\n",
        "          #prev_sum=summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjoaoOVXZcov",
        "outputId": "ce2433b6-94f0-4382-f683-33ecab73b940"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'testing': 0, 'saudi arabia': 0, 'syria': 15, 'canada': 1, 'turkey': 2, 'israel': 5, 'hungary': 0, 'north korea': 0, 'west island': 0, 'usgs': 0, 'china': 0, 'blenheim': 3, 'hong kong': 0, 'new zealand': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "####################\n",
            "Summary for 2023-02-22:\n",
            "####################\n",
            "Summaries for syria:\n",
            "rt @chuckcallesto: massive 300 km long crack earth's crust revealed turkey syria earthquake.. lokanta mediterranean grill &amp; bar donate sales made wednesday help earthquake victims turk...\n",
            "\n",
            "Summaries for israel:\n",
            "rt @qudsnen: turns israel contingent sent ostensibly 'help' victims turkey/syria earthquake loo... @brendanbeirne @jasonlemon maybe could write a shambles about the bombing of damascus, another famous serial killer state bombs northern part. earthquake hit, states murdered people. disgusting realities change? think media much hides fact\n",
            "\n",
            "Summaries for blenheim:\n",
            "m4.1 quake causing weak shaking near blenheim rt @geonet: m3.2 tremor resulting in weak shake near the city of st. johns-lee qc - earthquakes in europe and the pacific neo-nazis equanes in the west of the united states aquakes in germany and u.s. earthquake\n",
            "\n",
            "{'testing': 0, 'turkey': 3, 'syria': 9, 'iran': 0, 'usgs': 1, 'united states': 1, 'japan': 2, 'taipei': 2, 'india': 0}\n",
            "\n",
            "\n",
            "####################\n",
            "Summary for 2023-02-23:\n",
            "####################\n",
            "Summaries for turkey:\n",
            "kim woosung's 30th birthday project  turkey-syria earthquake support. rt: npr baklava took break turkey’s pastry capital earthquake. back to the page you came from - http://www.youtube.com/watch?v=1&q=3&src=0&t=2&ns=6&cs_id=4&p=5\n",
            "\n",
            "Summaries for syria:\n",
            "rt @crlioncter: ugly truth #earthquake #turkey #syria, always smart @aronlund \"if assad’s ear's normalization linchpin saudi arabia if turkish occupation escala...  #breaking tuesday @6newsau: despite disaster earthquake, dictator #erdogan plans launch invasion operation\n",
            "\n",
            "{'testing': 0, 'webinar': 0, 'indonesia': 0, 'syria': 14, 'israel': 4, 'cairo': 0, '🇹': 1, 'united states': 0, 'usgs': 2, 'miles).#tajikistan': 0, 'ashland county': 0, 'china': 2, 'turkey': 1, 'egypt': 1, 'newcastle': 0, 'uk': 1, 'india': 0, 'north halmahera': 0, 'suez governorate': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "####################\n",
            "Summary for 2023-02-24:\n",
            "####################\n",
            "Summaries for syria:\n",
            "rt @abc3340: death toll massive earthquake hit parts turkey syria feb. 6 continues rise bodies are... click support urgent! turkish earthquake relief organized danita cinquemani #gofundme please give love help heal lost loved ones like poor man.\n",
            "\n",
            "Summaries for israel:\n",
            "rt @hadinasrallah: one week israel bombed syria's capital.. id bombings in lebanese village massacred palestinians wes...\n",
            "\n",
            "{'testing': 0, 'india': 0, 'israel': 0, 'syria': 12, 'usgs': 2, 'mentasta lake': 0, 'united states': 0, 'australia': 0, 'canada': 0, 'iraq': 7, 'japan': 1, 'turkey': 2, '@raahiagbah': 0, 'egypt': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "####################\n",
            "Summary for 2023-02-25:\n",
            "####################\n",
            "Summaries for syria:\n",
            "rt @warmonitors: #breaking total earthquake death toll surpasses 50,000 turkey syria. ivan_8848: children protest western sanctions dozens parents children took streets damascus, dunya needs surgery 02/24/2023 choose link latest update. consider donating elevate prize winner'sana-mustafa-1' venmo: https://www.a\n",
            "\n",
            "Summaries for iraq:\n",
            "#earthquake (#) possibly felt 21 sec ago #iraq. colored dots represent local shaking &amp; damage level reported eyewitnesses.\n",
            "\n",
            "{'testing': 0, 'hungary': 0, 'sacramento': 0, 'japan': 5, 'turkey': 0, 'syria': 7, 'konya': 0, 'canada': 0, 'rt @gmrpetricca': 0, 'pakistan': 0, 'britain': 0, 'united kingdom': 0, 'lebanon': 0, 'california': 0, 'britain province': 0}\n",
            "\n",
            "\n",
            "####################\n",
            "Summary for 2023-02-26:\n",
            "####################\n",
            "Summaries for japan:\n",
            "rsoe edis: earthquake 6.1 magnitude hits northern japan, tsunami warns ua. earthquake struck hokkaido on tuesday, usgs read:  another earthquake #japanearthquake!breaking news: magnitude 6.9 earthquake shakes north pacific ocean; tsunami warnings issued for afp, nma and ibm - os\n",
            "\n",
            "Summaries for syria:\n",
            "syria's deadliest quake decade. #globalcrisis # #whitehouse one earthquake like took place. # # #   # pope francis' requests support people affected earthquake prayer concrete actions... #middleeast #newsdeskinbox #bisho    #... # #\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aw0vLCs_ZlRg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}